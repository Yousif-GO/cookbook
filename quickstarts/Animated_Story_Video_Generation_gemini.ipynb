{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "by [Yousif Ahmed](https://www.linkedin.com/in/yousif-hag-ahmed/) ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Gemini API: Animated Story Video Generation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1bGg17MHQMRke8n0ryH5WOu6uM56HZo-y?usp=sharing\"><img src=\"../images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "This Colab Notebook demonstrates how to generate an animated story video by:\n",
        "\n",
        "1. Generating a story sequence using structured Google Gemini API (for character consistency).\n",
        "2. Generating images for each scene using Google’s Imagen API.\n",
        "3. Synthesizing narration audio using Kokoro's KPipeline.\n",
        "4. Creating short video clips (image + audio overlay) for each scene.\n",
        "5. Combining all clips into one final video.\n",
        "6. Cleaning up temporary files after processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQJjzmYgH3sX",
        "outputId": "3c1b1a7f-4f7a-4741-da2a-35840fd10bec"
      },
      "outputs": [],
      "source": [
        "!pip install google-genai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iQSKjF5WH5N9"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Set up your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](../quickstarts/Authentication.ipynb) quickstart for an example.\n",
        "\n",
        "* Go to \"Tools\" -> \"command palette\" -> \"User secrets\" in the Colab menu.\n",
        "* Click \"Add a secret\".\n",
        "* In the \"Secret name\" field, enter GOOGLE_API_KEY.\n",
        "* In the \"Secret value\" field, paste your actual Google API key.\n",
        "* Click \"Add\" to save the secret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wltbMJLIIXGk"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['GOOGLE_API_KEY']=userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iipaJJsBeuBC"
      },
      "source": [
        "## Notebook Information\n",
        "\n",
        "This notebook, titled **Animated Story Video Generation**, uses multiple Google APIs and open source libraries to produce an animated video from a generated story sequence. The notebook demonstrates the integration of state‑of‑the‑art text, image, and audio generation methods along with video composition using MoviePy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GrX47ZZejZh"
      },
      "source": [
        "# **Code Cell 1: Installation and Setup Commands**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ_IJv0VegO6",
        "outputId": "478cb975-d090-4140-cc73-b7716f572c49"
      },
      "outputs": [],
      "source": [
        "\n",
        "!apt-get update -qq && apt-get install -qq locales\n",
        "!locale-gen en_US.UTF-8\n",
        "!update-locale LANG=en_US.UTF-8 LC_ALL=en_US.UTF-8\n",
        "\n",
        "!apt-get -qq -y install espeak-ng > /dev/null 2>&1\n",
        "!pip install -q google-generativeai moviepy Pillow\n",
        "!pip install -q nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isCm4c89hD3_",
        "outputId": "d97addaf-e10d-4f5d-a51a-579a020b59b0"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "import json\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from scipy.io.wavfile import write\n",
        "from io import BytesIO\n",
        "from moviepy.editor import ImageClip, TextClip, CompositeVideoClip, AudioFileClip, concatenate_videoclips\n",
        "import typing_extensions as typing\n",
        "from IPython.display import display, Audio\n",
        "import soundfile as sf\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "import asyncio\n",
        "import contextlib\n",
        "import json\n",
        "import wave\n",
        "from IPython import display\n",
        "from google import genai\n",
        "from google.genai import types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnQeb-SmhFh2"
      },
      "source": [
        "\n",
        "# Google Generative Models Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VXXqeYyIhBFm"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google import genai\n",
        "client = genai.Client(http_options= {\n",
        "      'api_version': 'v1alpha'\n",
        "})\n",
        "# Create a client for text generation using Gemini.\n",
        "MODEL = \"gemini-2.0-flash-exp\"\n",
        "# Create a client for image generation using Imagen.\n",
        "IMAGE_MODEL_ID = \"imagen-3.0-generate-002\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knBNtFw7hTz1"
      },
      "source": [
        "\n",
        "# SECTION 1: Story Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OimNe8lHhb4f"
      },
      "outputs": [],
      "source": [
        "# Define the structure for each story segment.\n",
        "class StorySegment(typing.TypedDict):\n",
        "    image_prompt: str\n",
        "    audio_text: str\n",
        "    character_description: str\n",
        "\n",
        "# Define the structure for the overall story response.\n",
        "class StoryResponse(typing.TypedDict):\n",
        "    complete_story: list[StorySegment]\n",
        "    pages: int\n",
        "\n",
        "def generate_story_sequence(complete_story: str, pages: int) -> list[StorySegment]:\n",
        "    \"\"\"\n",
        "    Generate a story sequence given a theme and number of scenes.\n",
        "    Each scene includes:\n",
        "      - image_prompt: short scene description\n",
        "      - audio_text: dialogue or narration text\n",
        "      - character_description: detailed character/background hints\n",
        "    \"\"\"\n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL,\n",
        "        contents=f'''you are an animation video producer. Generate a story sequence about {complete_story} in {pages} scenes (with interactions and characters), 1 sec each scene. Write:\n",
        "\n",
        "image_prompt: a full description of the scene, the characters in it, and the background in 20 words or less. Progressively shift the scene as the story advances.\n",
        "audio_text: a one-sentence dialogue/narration for the scene.\n",
        "character_description: no people ever, only animals and objects. Describe all characters (consistent names, features, clothing, etc.) with an art style reference (e.g., \"Pixar style,\" \"photorealistic,\" \"Ghibli\") in 30 words or less.\n",
        "''',\n",
        "        config={\n",
        "            'response_mime_type': 'application/json',\n",
        "            'response_schema': list[StoryResponse]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        story_data_text = response.text  # Get the JSON text\n",
        "        story_data_list = json.loads(story_data_text)\n",
        "        if isinstance(story_data_list, list) and len(story_data_list) > 0:\n",
        "            story_data = story_data_list[0]\n",
        "            return story_data.get('complete_story', []), story_data.get('character_description', {})\n",
        "        else:\n",
        "            return []\n",
        "    except (KeyError, TypeError, IndexError, json.JSONDecodeError) as e:\n",
        "        print(f\"Error parsing JSON: {e}\")\n",
        "        return []\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgL_I6hoq2cK"
      },
      "source": [
        "**Example usage: define a theme and generate scenes.**\n",
        "\n",
        "* write your own theme and num of scenes to play and experiment with it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzJhnJcwq1Rq",
        "outputId": "3a43a839-5c89-411c-ee9e-3d65fdae3f9c"
      },
      "outputs": [],
      "source": [
        "# example:\n",
        "# theme = \"cats and dogs\"\n",
        "# story_segments, _ = generate_story_sequence(theme, 3)\n",
        "\n",
        "# Get user input for theme and number of scenes in Colab.\n",
        "theme = input(\"Enter a theme for your animated story: \")\n",
        "num_scenes = int(input(\"Enter the number of scenes: \"))\n",
        "story_segments, _ = generate_story_sequence(theme, num_scenes)\n",
        "print(\"Generated story segments:\", story_segments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3RZNG0ehiOG"
      },
      "source": [
        "\n",
        "# SECTION 2: Process Each Story Segment and Create Video Clips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f1Ko_e8VR395"
      },
      "outputs": [],
      "source": [
        "@contextlib.contextmanager\n",
        "def wave_file(filename, channels=1, rate=24000, sample_width=2):\n",
        "    with wave.open(filename, \"wb\") as wf:\n",
        "        wf.setnchannels(channels)\n",
        "        wf.setsampwidth(sample_width)\n",
        "        wf.setframerate(rate)\n",
        "        yield wf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ala2K5ih9jW",
        "outputId": "3205dbe9-4703-4bf4-ddd2-cb89d822fdce"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# --- Cell 2: Definitions and setup ---\n",
        "temp_audio_files = []  # To track temporary audio files\n",
        "temp_image_files = []  # To track temporary image files\n",
        "video_clips = []       # To store individual video clips for each scene\n",
        "\n",
        "def generate_audio_live(api_text, output_filename):\n",
        "    import asyncio\n",
        "    collected_audio = bytearray()\n",
        "\n",
        "    async def _generate():\n",
        "        config = {\n",
        "            \"generation_config\": {\"response_modalities\": [\"AUDIO\"]}\n",
        "        }\n",
        "        # Connect to the Live API using the client already initialized above.\n",
        "        async with client.aio.live.connect(model=MODEL, config=config) as session:\n",
        "            # Send the audio_text prompt; mark as end_of_turn.\n",
        "            await session.send(input=api_text, end_of_turn=True)\n",
        "            # Collect audio data as it streams in.\n",
        "            async for response in session.receive():\n",
        "                if response.data:\n",
        "                    collected_audio.extend(response.data)\n",
        "        return bytes(collected_audio)\n",
        "\n",
        "    # Run the async function and collect the audio bytes.\n",
        "    audio_bytes = asyncio.run(_generate())\n",
        "    # Write the collected audio bytes into a WAV file using the helper.\n",
        "    with wave_file(output_filename) as wf:\n",
        "        wf.writeframes(audio_bytes)\n",
        "    return output_filename\n",
        "\n",
        "# --- Cell 3: Main processing loop ---\n",
        "for i, segment in enumerate(story_segments):\n",
        "    # Retrieve details for the current scene.\n",
        "    image_prompt = segment['image_prompt']\n",
        "    audio_negative_prompt = \"dont say OK , I will do this or that, just only read this story using voice expressions without introductions or ending ,more segments are comming ,dont say OK , I will do this or that:\\n\"\n",
        "    audio_text =  audio_negative_prompt + segment['audio_text']\n",
        "    audio_text_prompt = segment['audio_text']\n",
        "    char_desc = segment['character_description']\n",
        "\n",
        "    print(f\"Processing scene {i}:\")\n",
        "    print(\"Image Prompt:\", image_prompt)\n",
        "    print(\"Audio Text:\", audio_text_prompt)\n",
        "    print(\"Character Description:\", char_desc)\n",
        "    print(\"--------------------------------\")\n",
        "\n",
        "    # -------------------------\n",
        "    # Image Generation using Google Imagen\n",
        "    # -------------------------\n",
        "    combined_prompt = \"detailed children book animation style \" + image_prompt + \" \" + char_desc\n",
        "\n",
        "    result = client.models.generate_images(\n",
        "        model=IMAGE_MODEL_ID,\n",
        "        prompt=combined_prompt,\n",
        "        config={\n",
        "            \"number_of_images\": 1,\n",
        "            \"output_mime_type\": \"image/jpeg\",\n",
        "            \"person_generation\": \"DONT_ALLOW\",\n",
        "            \"aspect_ratio\": \"1:1\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        if not result.generated_images:\n",
        "            raise ValueError(\"No images were generated. The prompt might have been flagged as harmful. Please modify your prompt and try again.\")\n",
        "        for generated_image in result.generated_images:\n",
        "            image = Image.open(BytesIO(generated_image.image.image_bytes))\n",
        "    except Exception as e:\n",
        "        print(\"Image generation failed \", e)\n",
        "\n",
        "    image_path = f\"image_{i}.png\"\n",
        "    image.save(image_path)\n",
        "    temp_image_files.append(image_path)\n",
        "    image.show()\n",
        "\n",
        "    # -------------------------\n",
        "    # Audio Generation using Google Live API\n",
        "    # -------------------------\n",
        "    audio_path = f\"audio_{i}.wav\"\n",
        "    audio_path = generate_audio_live(audio_text, audio_path)\n",
        "    temp_audio_files.append(audio_path)\n",
        "\n",
        "\n",
        "    # -------------------------\n",
        "    # Create Video Clip (Image + Audio)\n",
        "    # -------------------------\n",
        "    audio_clip = AudioFileClip(audio_path)\n",
        "\n",
        "    # Convert PIL Image to numpy array\n",
        "    np_image = np.array(image)\n",
        "\n",
        "    # Create ImageClip (size is inferred from np_image)\n",
        "    image_clip = ImageClip(np_image).set_duration(audio_clip.duration)\n",
        "\n",
        "    # Store composite clip with audio in memory\n",
        "    composite_clip = CompositeVideoClip([image_clip]).set_audio(audio_clip)\n",
        "    video_clips.append(composite_clip)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y13_WC1rh_zk"
      },
      "source": [
        "\n",
        "# SECTION 3: Final Video Assembly and Cleanup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVXq-rjvegMa",
        "outputId": "87ce7dfa-9f1a-4b37-b09d-38a55d194e7d"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "final_video = concatenate_videoclips(video_clips)\n",
        "output_filename = f\"{int(time.time())}_output_video.mp4\"\n",
        "print(\"Writing final video to\", output_filename)\n",
        "final_video.write_videofile(output_filename, fps=24)\n",
        "\n",
        "# Cleanup: Close video clips and remove temporary files.\n",
        "final_video.close()\n",
        "for clip in video_clips:\n",
        "    clip.close()\n",
        "for file in temp_audio_files:\n",
        "    os.remove(file)\n",
        "for file in temp_image_files:\n",
        "    os.remove(file)\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6OjO-kiiNQl"
      },
      "source": [
        "## Final Notes\n",
        "\n",
        "This notebook is designed to run without modifications. It generates an animated story video using multiple Google APIs and open source libraries. Make sure to have a valid API key and to install all the necessary dependencies before running the notebook in Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4677dd58e9b5"
      },
      "source": [
        "## Next Steps\n",
        "### Useful API references:\n",
        "\n",
        "* Learn more about [Structured Outputs](https://ai.google.dev/gemini-api/docs/structured-outputs) in the docs.\n",
        "\n",
        "* [imagen pricing ](https://ai.google.dev/pricing#2_0flash)\n",
        "\n",
        "* Imagen prompt guide and [Prompt writing basics](https://ai.google.dev/gemini-api/docs/imagen-prompt-guide)\n",
        "\n",
        "### Related examples\n",
        "\n",
        "* [Get started imagen](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_imagen.ipynb)\n",
        "\n",
        "* [Get started LiveAPI](https://github.com/Yousif-GO/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb_)\n",
        "\n",
        "### Continue your discovery of the Gemini API\n",
        "\n",
        "checkout other great gemini features  \n",
        "\n",
        "* [video understanding](https://github.com/google-gemini/cookbook/blob/4437c15aa0bcb8f397b49f5b2e549f64e3a0985f/quickstarts/Video_understanding.ipynb)\n",
        "\n",
        "* [Prompting with video](https://github.com/google-gemini/cookbook/blob/4437c15aa0bcb8f397b49f5b2e549f64e3a0985f/quickstarts/Video.ipynb)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
